{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asl_cnn",
      "provenance": [],
      "authorship_tag": "ABX9TyPokVWgvFAoAnSDwodpZIl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rmbayer/ASL_NN/blob/master/asl_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6uupcCJN5RJ",
        "colab_type": "text"
      },
      "source": [
        "#CNN TensorFlow Framework for American Sign Language Detection\n",
        "### **Bob Bayer and Jonathan Rice 2020**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "901jIDuWOP2K",
        "colab_type": "text"
      },
      "source": [
        "**Retrieve Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBgVXfJmN4Mq",
        "colab_type": "code",
        "outputId": "a7bef34e-151b-4d25-9be7-c6286bd24fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Import and mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzvvfm25UT84",
        "colab_type": "code",
        "outputId": "a1003ddf-e2f8-463c-f835-e2cccc1e8fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Check drive contents\n",
        "!ls \"/content/drive/My Drive/Sign Language\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " asl-alphabet.zip\t\t      'Sign Language Project Research.gdoc'\n",
            "'ASL Recognition with Deep Learning'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAwCZynId9_z",
        "colab_type": "text"
      },
      "source": [
        "**The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4vpEj2QQ--B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/content/drive/My Drive/Sign Language/asl-alphabet.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "# Extract to a local file and close the connection to the drive file\n",
        "zip_ref.extractall('/tmp/') \n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ZihcBRd4yf",
        "colab_type": "text"
      },
      "source": [
        "**Set the directories for the training and test datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxIs9CHgeNcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join('/tmp/asl_alphabet_train/asl_alphabet_train')\n",
        "test_dir= os.path.join('/tmp/asl_alphabet_test/asl_alphabet_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHU9EFzmogF-",
        "colab_type": "text"
      },
      "source": [
        "**Veryify the subfolders of the directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Vsb51mfRb9",
        "colab_type": "code",
        "outputId": "7fa6b185-f6bc-4914-b2cd-4759e7c146ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_names = os.listdir(train_dir)\n",
        "print(train_names)\n",
        "test_names = os.listdir(train_dir)\n",
        "print(test_names)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'G', 'S', 'W', 'N', 'L', 'H', 'X', 'K', 'V', 'P', 'I', 'T', 'B', 'C', 'R', 'del', 'J', 'F', 'D', 'Z', 'space', 'E', 'Q', 'M', 'U', 'Y', 'nothing', 'O']\n",
            "['A', 'G', 'S', 'W', 'N', 'L', 'H', 'X', 'K', 'V', 'P', 'I', 'T', 'B', 'C', 'R', 'del', 'J', 'F', 'D', 'Z', 'space', 'E', 'Q', 'M', 'U', 'Y', 'nothing', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZnqjBM3rTN5",
        "colab_type": "text"
      },
      "source": [
        "**Build the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIpch_TerZq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1WW83M3oROD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    #tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 128 neuron hidden layer\n",
        "    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(29, activation = tf.nn.softmax)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS0BKMRPtbAI",
        "colab_type": "text"
      },
      "source": [
        "**Inspect the Layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r12aDWCfrfFd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "a8bbb496-f7b4-4c8f-b8ad-3ff48e82a004"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 198, 198, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 99, 99, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 97, 97, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 33856)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               4333696   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29)                3741      \n",
            "=================================================================\n",
            "Total params: 4,361,021\n",
            "Trainable params: 4,361,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d-RqS69teGY",
        "colab_type": "text"
      },
      "source": [
        "**Set the optimizer** <br>\n",
        "Use adam for it's adaptive learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bQcbgK6rfIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5upIJU0o8I7",
        "colab_type": "text"
      },
      "source": [
        "**Define the ImageGenerator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cslF61L7kSiE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ce27595-fd07-43f2-d514-f4c1542972db"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,  # This is the source directory for training images\n",
        "        target_size=(200, 200),\n",
        "        batch_size=100,\n",
        "        # Since we use categorical_crossentropy loss, we need sparse labels\n",
        "        class_mode='sparse')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 87000 images belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QodatZkxtWPl",
        "colab_type": "text"
      },
      "source": [
        "**Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b82HI0xStU-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "12336630-6314-4714-a232-5bd1f9e5cbc0"
      },
      "source": [
        "model.fit(train_generator, \n",
        "          steps_per_epoch = 870, #we have 87,000 images, batch size of 100\n",
        "          epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "870/870 [==============================] - 166s 190ms/step - loss: 0.0436 - accuracy: 0.9863\n",
            "Epoch 2/10\n",
            "870/870 [==============================] - 169s 194ms/step - loss: 0.0312 - accuracy: 0.9903\n",
            "Epoch 3/10\n",
            "870/870 [==============================] - 171s 196ms/step - loss: 0.0260 - accuracy: 0.9919\n",
            "Epoch 4/10\n",
            "294/870 [=========>....................] - ETA: 1:53 - loss: 0.0120 - accuracy: 0.9962"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Cblro2od7J",
        "colab_type": "text"
      },
      "source": [
        "***Debugging***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nMlNeo0ewkm",
        "colab_type": "code",
        "outputId": "30adbb52-951f-46c8-8d5d-75a430142d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#!ls '/tmp/'\n",
        "#!ls '/tmp/asl-alphabet/'\n",
        "!ls '/tmp/asl_alphabet_train/'\n",
        "!ls '/tmp/asl_alphabet_train/asl_alphabet_train'\n",
        "#!ls '/tmp/asl-alphabet/asl_alphabet_train/asl_alphabet_test'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asl_alphabet_train\n",
            "A  C  del  F  H  J  L  N\tO  Q  S      T\tV  X  Z\n",
            "B  D  E    G  I  K  M  nothing\tP  R  space  U\tW  Y\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}